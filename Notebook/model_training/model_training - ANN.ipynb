{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5490313b",
   "metadata": {},
   "source": [
    "## Model training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c9cb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14400\\1337451595.py:20: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# import necessory packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow\n",
    "import keras_tuner\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras import optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784d86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cleaned data\n",
    "data = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de923e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61270bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91fe534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f544d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand_names           0\n",
       "price                 0\n",
       "score               420\n",
       "processor brand       0\n",
       "processor type        4\n",
       "processor gen       101\n",
       "type of core         23\n",
       "no of threads         0\n",
       "Ram                   0\n",
       "ram type              1\n",
       "storage type          0\n",
       "storage capacity      8\n",
       "ppi                  34\n",
       "OS                    0\n",
       "Warranty             86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f27082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1016 entries, 0 to 1015\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   brand_names       1016 non-null   object \n",
      " 1   price             1016 non-null   int64  \n",
      " 2   score             596 non-null    float64\n",
      " 3   processor brand   1016 non-null   object \n",
      " 4   processor type    1012 non-null   object \n",
      " 5   processor gen     915 non-null    float64\n",
      " 6   type of core      993 non-null    float64\n",
      " 7   no of threads     1016 non-null   float64\n",
      " 8   Ram               1016 non-null   int64  \n",
      " 9   ram type          1015 non-null   object \n",
      " 10  storage type      1016 non-null   object \n",
      " 11  storage capacity  1008 non-null   float64\n",
      " 12  ppi               982 non-null    float64\n",
      " 13  OS                1016 non-null   object \n",
      " 14  Warranty          930 non-null    float64\n",
      "dtypes: float64(7), int64(2), object(6)\n",
      "memory usage: 119.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456443ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = [col for col in df if df[col].dtypes!='O']\n",
    "cat_col = [col for col in df if df[col].dtypes=='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8846ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'score',\n",
       " 'processor gen',\n",
       " 'type of core',\n",
       " 'no of threads',\n",
       " 'Ram',\n",
       " 'storage capacity',\n",
       " 'ppi',\n",
       " 'Warranty']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd97b75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score',\n",
       " 'processor gen',\n",
       " 'type of core',\n",
       " 'no of threads',\n",
       " 'Ram',\n",
       " 'storage capacity',\n",
       " 'ppi',\n",
       " 'Warranty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b927d68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand_names',\n",
       " 'processor brand',\n",
       " 'processor type',\n",
       " 'ram type',\n",
       " 'storage type',\n",
       " 'OS']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d675e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e37e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessor = Pipeline(steps=[\n",
    "                                        (\"scaler\", RobustScaler()),\n",
    "                                        (\"imputation_mean\",SimpleImputer(missing_values=np.nan, strategy=\"mean\"))\n",
    "                                      ])\n",
    "\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "                                            (\"imputer\",SimpleImputer(strategy=\"constant\")),\n",
    "                                            (\"encoder\", OneHotEncoder(sparse=False,drop='first',handle_unknown=\"ignore\")),\n",
    "                                        ])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "                                    (\"categorical\", categorical_preprocessor, cat_col),\n",
    "                                    (\"numerical\", numeric_preprocessor,  num_col[1:]),\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13fce4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e7cfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa551cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed the preprocessed data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c437b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812, 44)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac738717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "model = Sequential([\n",
    "                    Dense(256,kernel_initializer = 'he_uniform',activation='relu',input_dim = 44),\n",
    "                    Dense(128,kernel_initializer = 'he_uniform',activation='relu'),\n",
    "                    Dense(128,kernel_initializer = 'he_uniform',activation='relu'),\n",
    "                    Dense(96,kernel_initializer = 'he_uniform',activation='relu'),\n",
    "                    Dense(1,activation = 'linear')\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bcfd9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53ab2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the preprocessor and model into a single pipeline\n",
    "regressor = Pipeline(steps=[('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc64e8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 2s 16ms/step - loss: 10586697728.0000 - val_loss: 7981934592.0000\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 8491916800.0000 - val_loss: 6130285568.0000\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 6457804800.0000 - val_loss: 6022047232.0000\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 6137444352.0000 - val_loss: 5971638784.0000\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 6168901632.0000 - val_loss: 5934956032.0000\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 6007421952.0000 - val_loss: 5850868224.0000\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 6067443200.0000 - val_loss: 5766993920.0000\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 5880813056.0000 - val_loss: 5713531392.0000\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 5842186752.0000 - val_loss: 5551281664.0000\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 5604077568.0000 - val_loss: 5390063104.0000\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 5480772608.0000 - val_loss: 5130746880.0000\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 5153979904.0000 - val_loss: 4793159680.0000\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 4700718592.0000 - val_loss: 4290478848.0000\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 4378631168.0000 - val_loss: 3944500992.0000\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 3839516672.0000 - val_loss: 2813559296.0000\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2627282944.0000 - val_loss: 1936871680.0000\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1916403840.0000 - val_loss: 1432816640.0000\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1656932864.0000 - val_loss: 1476096896.0000\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1463160320.0000 - val_loss: 1186554624.0000\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1449191552.0000 - val_loss: 1169715328.0000\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1351160960.0000 - val_loss: 1201874048.0000\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1326988160.0000 - val_loss: 1120060160.0000\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1335196416.0000 - val_loss: 1164410240.0000\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1324780800.0000 - val_loss: 1144184192.0000\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1378439808.0000 - val_loss: 1045881344.0000\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1273616640.0000 - val_loss: 1051908800.0000\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1222659072.0000 - val_loss: 1018777920.0000\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1230425856.0000 - val_loss: 984116672.0000\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1209125376.0000 - val_loss: 1035286272.0000\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1190622976.0000 - val_loss: 1029447360.0000\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1184118016.0000 - val_loss: 975202880.0000\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1177138944.0000 - val_loss: 982312704.0000\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1174676224.0000 - val_loss: 937349312.0000\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1136761472.0000 - val_loss: 914244544.0000\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1165915136.0000 - val_loss: 954790464.0000\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1151967232.0000 - val_loss: 970917696.0000\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1121878912.0000 - val_loss: 905931584.0000\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1128629504.0000 - val_loss: 904353152.0000\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1110638976.0000 - val_loss: 858250432.0000\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1127300224.0000 - val_loss: 896737408.0000\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1131844736.0000 - val_loss: 844926720.0000\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1098433280.0000 - val_loss: 904435904.0000\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1074273280.0000 - val_loss: 863472000.0000\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1113592320.0000 - val_loss: 821541888.0000\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1027958272.0000 - val_loss: 845731776.0000\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1053941952.0000 - val_loss: 884461184.0000\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1056084160.0000 - val_loss: 885493824.0000\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1051084800.0000 - val_loss: 825882368.0000\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1036258752.0000 - val_loss: 807913024.0000\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1012646912.0000 - val_loss: 786222464.0000\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1065712320.0000 - val_loss: 808482560.0000\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1038065728.0000 - val_loss: 1009276992.0000\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1088297984.0000 - val_loss: 782748544.0000\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1023267776.0000 - val_loss: 762807104.0000\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1001439360.0000 - val_loss: 763580352.0000\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1014430336.0000 - val_loss: 765012864.0000\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 998695424.0000 - val_loss: 748126848.0000\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 977758720.0000 - val_loss: 769621760.0000\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 989767488.0000 - val_loss: 858409664.0000\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1034159488.0000 - val_loss: 913212864.0000\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 959968320.0000 - val_loss: 732193920.0000\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1019487616.0000 - val_loss: 783373120.0000\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1059809536.0000 - val_loss: 745238400.0000\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1042286848.0000 - val_loss: 916125056.0000\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1015711040.0000 - val_loss: 824777088.0000\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 999643776.0000 - val_loss: 772970560.0000\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 957076608.0000 - val_loss: 767182656.0000\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 962227584.0000 - val_loss: 716001920.0000\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 930461632.0000 - val_loss: 714871232.0000\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 921557824.0000 - val_loss: 744323136.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 919451840.0000 - val_loss: 705321664.0000\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 937838016.0000 - val_loss: 729993152.0000\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 914582976.0000 - val_loss: 747436352.0000\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 922052800.0000 - val_loss: 716935808.0000\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 950055616.0000 - val_loss: 726671872.0000\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1072996736.0000 - val_loss: 706809088.0000\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 990000576.0000 - val_loss: 686836032.0000\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 980750784.0000 - val_loss: 734973376.0000\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 898246016.0000 - val_loss: 717894784.0000\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 897600320.0000 - val_loss: 727534144.0000\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 945460160.0000 - val_loss: 714503040.0000\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1000329984.0000 - val_loss: 901351872.0000\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 956370240.0000 - val_loss: 768948160.0000\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 990405184.0000 - val_loss: 757462592.0000\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 929299456.0000 - val_loss: 683306944.0000\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 982327104.0000 - val_loss: 660310400.0000\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 968634112.0000 - val_loss: 670011904.0000\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 889594880.0000 - val_loss: 672159424.0000\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 982498432.0000 - val_loss: 670396352.0000\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 907276480.0000 - val_loss: 676209984.0000\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 871660608.0000 - val_loss: 656944320.0000\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 879086592.0000 - val_loss: 704576320.0000\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 871901760.0000 - val_loss: 670223488.0000\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 870088960.0000 - val_loss: 672017088.0000\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 861882624.0000 - val_loss: 646333696.0000\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 926881152.0000 - val_loss: 673871232.0000\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 874530432.0000 - val_loss: 646393408.0000\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 871582144.0000 - val_loss: 669900032.0000\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 858459968.0000 - val_loss: 638226368.0000\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 860540096.0000 - val_loss: 658111424.0000\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 942976640.0000 - val_loss: 850623040.0000\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 976685376.0000 - val_loss: 657033856.0000\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 917995328.0000 - val_loss: 669305984.0000\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 901404096.0000 - val_loss: 649009600.0000\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 848678784.0000 - val_loss: 646599872.0000\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 862198656.0000 - val_loss: 659202304.0000\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 850403968.0000 - val_loss: 686207488.0000\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 842581184.0000 - val_loss: 764779776.0000\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 877686016.0000 - val_loss: 718670080.0000\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 883897408.0000 - val_loss: 642503296.0000\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 869529920.0000 - val_loss: 634442304.0000\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 855716352.0000 - val_loss: 861679040.0000\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 886146368.0000 - val_loss: 680632704.0000\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 856556928.0000 - val_loss: 631211328.0000\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 860515328.0000 - val_loss: 670315776.0000\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 839512448.0000 - val_loss: 822693312.0000\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1024249344.0000 - val_loss: 670486848.0000\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 851584448.0000 - val_loss: 646534528.0000\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 816894528.0000 - val_loss: 652179584.0000\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 823672192.0000 - val_loss: 655904512.0000\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 842636800.0000 - val_loss: 704920576.0000\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 854190720.0000 - val_loss: 643526464.0000\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 809956032.0000 - val_loss: 637586688.0000\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 811824320.0000 - val_loss: 660530048.0000\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 837018176.0000 - val_loss: 684537728.0000\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 851822976.0000 - val_loss: 687408640.0000\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 888716800.0000 - val_loss: 648624064.0000\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 803530752.0000 - val_loss: 652074048.0000\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 834802496.0000 - val_loss: 620617728.0000\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 799097280.0000 - val_loss: 656841536.0000\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 815303616.0000 - val_loss: 634054208.0000\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 801635776.0000 - val_loss: 636209024.0000\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 877450112.0000 - val_loss: 691626816.0000\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 985200192.0000 - val_loss: 842662656.0000\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 883494208.0000 - val_loss: 829447552.0000\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 794695168.0000 - val_loss: 629027840.0000\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 813740480.0000 - val_loss: 684128512.0000\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 917602752.0000 - val_loss: 1027425728.0000\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1113016960.0000 - val_loss: 847064256.0000\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 890940928.0000 - val_loss: 635987072.0000\n",
      "Epoch 141/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 813032192.0000 - val_loss: 648929664.0000\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 791815424.0000 - val_loss: 659853312.0000\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 788413888.0000 - val_loss: 630748032.0000\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 886962112.0000 - val_loss: 630549888.0000\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 799401472.0000 - val_loss: 641238784.0000\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 801024384.0000 - val_loss: 642449600.0000\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 801622592.0000 - val_loss: 645132480.0000\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 825632704.0000 - val_loss: 638051136.0000\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 783987136.0000 - val_loss: 641188160.0000\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 824655168.0000 - val_loss: 646561216.0000\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 785007104.0000 - val_loss: 659192640.0000\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 773840512.0000 - val_loss: 656437888.0000\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 797481728.0000 - val_loss: 650091776.0000\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 802160256.0000 - val_loss: 634807616.0000\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 790460672.0000 - val_loss: 709912640.0000\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 791486528.0000 - val_loss: 638238400.0000\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 825315584.0000 - val_loss: 628107328.0000\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 870176768.0000 - val_loss: 626873664.0000\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 834359424.0000 - val_loss: 877045824.0000\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 984286912.0000 - val_loss: 760164352.0000\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 799603136.0000 - val_loss: 655100480.0000\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 768492864.0000 - val_loss: 654836672.0000\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 763798528.0000 - val_loss: 628968640.0000\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 794557440.0000 - val_loss: 635293440.0000\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 797467968.0000 - val_loss: 635914624.0000\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 811675264.0000 - val_loss: 625409728.0000\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 779800320.0000 - val_loss: 656828480.0000\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 827039936.0000 - val_loss: 705567488.0000\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 827770944.0000 - val_loss: 659910144.0000\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 765139136.0000 - val_loss: 616787520.0000\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 763198784.0000 - val_loss: 777235648.0000\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 797633920.0000 - val_loss: 665657216.0000\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 745915968.0000 - val_loss: 620434688.0000\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 814534400.0000 - val_loss: 696286720.0000\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 779904640.0000 - val_loss: 747622144.0000\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 770377088.0000 - val_loss: 658273216.0000\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 740865408.0000 - val_loss: 635918912.0000\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 753619904.0000 - val_loss: 634244992.0000\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 761508864.0000 - val_loss: 639345984.0000\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 766976000.0000 - val_loss: 649441024.0000\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 744353856.0000 - val_loss: 634684800.0000\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 748003008.0000 - val_loss: 631040832.0000\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 773931392.0000 - val_loss: 635684160.0000\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 837296320.0000 - val_loss: 760491136.0000\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 764523456.0000 - val_loss: 719634304.0000\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 752460672.0000 - val_loss: 668173568.0000\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 756259584.0000 - val_loss: 694602880.0000\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 774690304.0000 - val_loss: 653526720.0000\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 810783552.0000 - val_loss: 638045056.0000\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 806817280.0000 - val_loss: 628518912.0000\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 752775616.0000 - val_loss: 648949824.0000\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 790078464.0000 - val_loss: 730470976.0000\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 770967232.0000 - val_loss: 636628352.0000\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 757121472.0000 - val_loss: 633965184.0000\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 755746688.0000 - val_loss: 643308032.0000\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1026033152.0000 - val_loss: 674149376.0000\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 771542720.0000 - val_loss: 643576192.0000\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 743477248.0000 - val_loss: 663302272.0000\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 811397056.0000 - val_loss: 637027648.0000\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 731438208.0000 - val_loss: 668156032.0000\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 782516096.0000 - val_loss: 671253760.0000\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 749923456.0000 - val_loss: 645235712.0000\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 829774784.0000 - val_loss: 700939648.0000\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 866473088.0000 - val_loss: 632949952.0000\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 713692800.0000 - val_loss: 740144448.0000\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 778294208.0000 - val_loss: 705545408.0000\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 756660416.0000 - val_loss: 731027776.0000\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 790360192.0000 - val_loss: 643197440.0000\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 740519808.0000 - val_loss: 649629312.0000\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 733481024.0000 - val_loss: 680604992.0000\n",
      "Epoch 211/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 799754688.0000 - val_loss: 787704384.0000\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 810928000.0000 - val_loss: 666828736.0000\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 734398400.0000 - val_loss: 679273408.0000\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 771762176.0000 - val_loss: 691696192.0000\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 733800704.0000 - val_loss: 659341248.0000\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 732807232.0000 - val_loss: 706766656.0000\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 746122816.0000 - val_loss: 675338816.0000\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 763892992.0000 - val_loss: 677847296.0000\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 720117568.0000 - val_loss: 656744192.0000\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 723797440.0000 - val_loss: 663210496.0000\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 719280704.0000 - val_loss: 671516160.0000\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 709767296.0000 - val_loss: 637280512.0000\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 737101376.0000 - val_loss: 638343616.0000\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 731620416.0000 - val_loss: 659663872.0000\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 730599808.0000 - val_loss: 795885120.0000\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 784260864.0000 - val_loss: 708295808.0000\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 767633856.0000 - val_loss: 643421376.0000\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 733434304.0000 - val_loss: 648254976.0000\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 722826560.0000 - val_loss: 649782016.0000\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 796557760.0000 - val_loss: 634847808.0000\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 726346240.0000 - val_loss: 648865664.0000\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 789180160.0000 - val_loss: 761078144.0000\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 750785280.0000 - val_loss: 709840896.0000\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 721469184.0000 - val_loss: 634821824.0000\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 735734016.0000 - val_loss: 687122240.0000\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 745013888.0000 - val_loss: 669041984.0000\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 725201920.0000 - val_loss: 642837696.0000\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 727576512.0000 - val_loss: 674709120.0000\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 710487104.0000 - val_loss: 675608704.0000\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 719612800.0000 - val_loss: 671283712.0000\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 772979776.0000 - val_loss: 854920320.0000\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 789090560.0000 - val_loss: 711755072.0000\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 717847168.0000 - val_loss: 667491584.0000\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 702005184.0000 - val_loss: 665852032.0000\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 766685504.0000 - val_loss: 731171328.0000\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 702032064.0000 - val_loss: 646449280.0000\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 706240256.0000 - val_loss: 641859840.0000\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 712598464.0000 - val_loss: 643799552.0000\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 1009677376.0000 - val_loss: 840658496.0000\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1103388416.0000 - val_loss: 648552832.0000\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 974816960.0000 - val_loss: 670860416.0000\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 905781824.0000 - val_loss: 660922560.0000\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 752015872.0000 - val_loss: 632281344.0000\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 704788608.0000 - val_loss: 661210624.0000\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 729820864.0000 - val_loss: 720180608.0000\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 779309312.0000 - val_loss: 633386624.0000\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 715695936.0000 - val_loss: 641714048.0000\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 710255808.0000 - val_loss: 656861888.0000\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 713363520.0000 - val_loss: 677893568.0000\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 697434496.0000 - val_loss: 674139776.0000\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 701059456.0000 - val_loss: 638322560.0000\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 725506048.0000 - val_loss: 699962496.0000\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 808577024.0000 - val_loss: 751378688.0000\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 714912192.0000 - val_loss: 663364032.0000\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 706189504.0000 - val_loss: 733587520.0000\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 746012864.0000 - val_loss: 642780160.0000\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 731265536.0000 - val_loss: 635966784.0000\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 695940928.0000 - val_loss: 667188032.0000\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 682122240.0000 - val_loss: 728711488.0000\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 698572160.0000 - val_loss: 644115200.0000\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 729586048.0000 - val_loss: 650807552.0000\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 769488000.0000 - val_loss: 647856704.0000\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 765069184.0000 - val_loss: 637418560.0000\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 741905536.0000 - val_loss: 659744320.0000\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 868940800.0000 - val_loss: 822089024.0000\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 838256320.0000 - val_loss: 824533376.0000\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 905710464.0000 - val_loss: 984019392.0000\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 873379840.0000 - val_loss: 788993984.0000\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 726807232.0000 - val_loss: 713145216.0000\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 774449664.0000 - val_loss: 761565824.0000\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 847465024.0000 - val_loss: 670665536.0000\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 896250368.0000 - val_loss: 665600128.0000\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 711540416.0000 - val_loss: 635275200.0000\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 683568768.0000 - val_loss: 671301952.0000\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 713665408.0000 - val_loss: 657195008.0000\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 703358464.0000 - val_loss: 660709760.0000\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 692693312.0000 - val_loss: 661648640.0000\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 685218944.0000 - val_loss: 656543680.0000\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 681218624.0000 - val_loss: 704740416.0000\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 678414080.0000 - val_loss: 654494016.0000\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 673221184.0000 - val_loss: 753299648.0000\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 686778176.0000 - val_loss: 654646464.0000\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 676583552.0000 - val_loss: 741833984.0000\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 707953856.0000 - val_loss: 731108736.0000\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 681712128.0000 - val_loss: 730596544.0000\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 712450176.0000 - val_loss: 640078464.0000\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 780550080.0000 - val_loss: 647049856.0000\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 677707264.0000 - val_loss: 688901696.0000\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 686582848.0000 - val_loss: 718502848.0000\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 697782464.0000 - val_loss: 730859328.0000\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 746112640.0000 - val_loss: 698311168.0000\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 696064000.0000 - val_loss: 644479744.0000\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 724884736.0000 - val_loss: 692435136.0000\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 682092736.0000 - val_loss: 655264192.0000\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 691002112.0000 - val_loss: 655179968.0000\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 713940992.0000 - val_loss: 646379776.0000\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 674168896.0000 - val_loss: 636028096.0000\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 730596352.0000 - val_loss: 638659136.0000\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 713427456.0000 - val_loss: 684876608.0000\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 661053248.0000 - val_loss: 690284800.0000\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 738027520.0000 - val_loss: 714660992.0000\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 819890304.0000 - val_loss: 680080448.0000\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 697639936.0000 - val_loss: 671419200.0000\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 747828416.0000 - val_loss: 672304320.0000\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 798742912.0000 - val_loss: 637950080.0000\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 776653824.0000 - val_loss: 658462848.0000\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 713245440.0000 - val_loss: 680001472.0000\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 665339392.0000 - val_loss: 657276928.0000\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 668080448.0000 - val_loss: 653933504.0000\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 719835904.0000 - val_loss: 660834560.0000\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 665641600.0000 - val_loss: 808305216.0000\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 718351616.0000 - val_loss: 744802816.0000\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 725309824.0000 - val_loss: 676033920.0000\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 652112576.0000 - val_loss: 689768192.0000\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 666313472.0000 - val_loss: 711454656.0000\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 654674944.0000 - val_loss: 752682368.0000\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 672256192.0000 - val_loss: 751859200.0000\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 679616128.0000 - val_loss: 664198528.0000\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 657289600.0000 - val_loss: 645934208.0000\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 708384064.0000 - val_loss: 639595840.0000\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 674367552.0000 - val_loss: 657574464.0000\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 668158592.0000 - val_loss: 736183488.0000\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 707204160.0000 - val_loss: 716050560.0000\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 664330240.0000 - val_loss: 652521472.0000\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 650561216.0000 - val_loss: 665492736.0000\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 649391168.0000 - val_loss: 683066240.0000\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 657022336.0000 - val_loss: 676544640.0000\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 675339328.0000 - val_loss: 712656704.0000\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 670990400.0000 - val_loss: 681836160.0000\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 649314176.0000 - val_loss: 669008128.0000\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 701465792.0000 - val_loss: 666637056.0000\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 709432448.0000 - val_loss: 777386176.0000\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 742979904.0000 - val_loss: 748956160.0000\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 675194816.0000 - val_loss: 669096640.0000\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 637769280.0000 - val_loss: 691169088.0000\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 661812160.0000 - val_loss: 666227968.0000\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 651130112.0000 - val_loss: 652570816.0000\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 673415232.0000 - val_loss: 702048896.0000\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 664499712.0000 - val_loss: 654697920.0000\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 679578496.0000 - val_loss: 670871936.0000\n",
      "Epoch 351/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 648596352.0000 - val_loss: 666714752.0000\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 641004160.0000 - val_loss: 703196736.0000\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 637931200.0000 - val_loss: 689653824.0000\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 646260160.0000 - val_loss: 672701248.0000\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 697575616.0000 - val_loss: 650011776.0000\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 708170496.0000 - val_loss: 656178816.0000\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 633414912.0000 - val_loss: 659052736.0000\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 647027072.0000 - val_loss: 652126464.0000\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 703344640.0000 - val_loss: 662908096.0000\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 649804416.0000 - val_loss: 664375872.0000\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 651441920.0000 - val_loss: 659264576.0000\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 626941440.0000 - val_loss: 662177856.0000\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 665966400.0000 - val_loss: 688675392.0000\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 653526848.0000 - val_loss: 736890880.0000\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 616289216.0000 - val_loss: 653502592.0000\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 633060352.0000 - val_loss: 652037504.0000\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 638352704.0000 - val_loss: 740474112.0000\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 650794240.0000 - val_loss: 679240320.0000\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 654827328.0000 - val_loss: 661036288.0000\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 643523136.0000 - val_loss: 668020800.0000\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 628683392.0000 - val_loss: 727410496.0000\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 659300480.0000 - val_loss: 655290752.0000\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 664924032.0000 - val_loss: 647806336.0000\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 604536320.0000 - val_loss: 651300096.0000\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 632772160.0000 - val_loss: 654060800.0000\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 611040576.0000 - val_loss: 681690944.0000\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 623338368.0000 - val_loss: 656151488.0000\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 627400704.0000 - val_loss: 642198016.0000\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 644570048.0000 - val_loss: 660616832.0000\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 684759168.0000 - val_loss: 693997632.0000\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 663896896.0000 - val_loss: 670055104.0000\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 681529536.0000 - val_loss: 675221504.0000\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 623380544.0000 - val_loss: 667718528.0000\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 732933120.0000 - val_loss: 638751552.0000\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 686597824.0000 - val_loss: 680478592.0000\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 685668608.0000 - val_loss: 650857600.0000\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 710650560.0000 - val_loss: 679184512.0000\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 620116992.0000 - val_loss: 647382080.0000\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 608617280.0000 - val_loss: 699292480.0000\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 625662912.0000 - val_loss: 668777536.0000\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 614451648.0000 - val_loss: 701113536.0000\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 592518976.0000 - val_loss: 656616640.0000\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 610340864.0000 - val_loss: 649157760.0000\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 598629952.0000 - val_loss: 671643264.0000\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 611902528.0000 - val_loss: 669058240.0000\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 631584320.0000 - val_loss: 679888640.0000\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 653422208.0000 - val_loss: 709719360.0000\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 594806144.0000 - val_loss: 640767360.0000\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 637995840.0000 - val_loss: 640493824.0000\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 648989632.0000 - val_loss: 666810496.0000\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 618038656.0000 - val_loss: 679827520.0000\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 609751104.0000 - val_loss: 668077056.0000\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 732149888.0000 - val_loss: 904224128.0000\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 722178624.0000 - val_loss: 859525888.0000\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 749443072.0000 - val_loss: 740405440.0000\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 603625344.0000 - val_loss: 656628736.0000\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 603002560.0000 - val_loss: 656358080.0000\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 586256512.0000 - val_loss: 658070272.0000\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 581085120.0000 - val_loss: 700396288.0000\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 636696384.0000 - val_loss: 733919936.0000\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 580772928.0000 - val_loss: 658602880.0000\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 590204224.0000 - val_loss: 659485952.0000\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 602732992.0000 - val_loss: 685310528.0000\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 734429248.0000 - val_loss: 684152512.0000\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 596250112.0000 - val_loss: 654770048.0000\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 604639680.0000 - val_loss: 702688000.0000\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 643184768.0000 - val_loss: 685985152.0000\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 565927424.0000 - val_loss: 669278080.0000\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 593641024.0000 - val_loss: 650124096.0000\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 580237632.0000 - val_loss: 662907776.0000\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 7ms/step - loss: 572116352.0000 - val_loss: 683284544.0000\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 573981568.0000 - val_loss: 660954688.0000\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 564995328.0000 - val_loss: 689914304.0000\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 595600192.0000 - val_loss: 666006720.0000\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 576140928.0000 - val_loss: 686418048.0000\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 588345280.0000 - val_loss: 669544832.0000\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 578140864.0000 - val_loss: 694643712.0000\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 608303360.0000 - val_loss: 683918976.0000\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 636095680.0000 - val_loss: 693914176.0000\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 568632576.0000 - val_loss: 666819136.0000\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 579578304.0000 - val_loss: 665149312.0000\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 583144768.0000 - val_loss: 724343744.0000\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 632494848.0000 - val_loss: 842663488.0000\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 753364608.0000 - val_loss: 707149632.0000\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 544316992.0000 - val_loss: 664755136.0000\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 600984512.0000 - val_loss: 646475008.0000\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 597404032.0000 - val_loss: 672871680.0000\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 601570304.0000 - val_loss: 696702464.0000\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 597412672.0000 - val_loss: 662790208.0000\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 556172352.0000 - val_loss: 675209344.0000\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 585739968.0000 - val_loss: 665573440.0000\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 559594368.0000 - val_loss: 699991104.0000\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 580540800.0000 - val_loss: 665681664.0000\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 558753920.0000 - val_loss: 662889088.0000\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 560090048.0000 - val_loss: 693376704.0000\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 612984960.0000 - val_loss: 682185024.0000\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 558423168.0000 - val_loss: 681157184.0000\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 550126528.0000 - val_loss: 680338688.0000\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 583525248.0000 - val_loss: 648107968.0000\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 546831936.0000 - val_loss: 682125824.0000\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 571513152.0000 - val_loss: 655426624.0000\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 591519424.0000 - val_loss: 665121088.0000\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 635118464.0000 - val_loss: 679173056.0000\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 564316992.0000 - val_loss: 696848192.0000\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 617764672.0000 - val_loss: 670331072.0000\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 593390784.0000 - val_loss: 708329664.0000\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 599296128.0000 - val_loss: 675828544.0000\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 565513408.0000 - val_loss: 651906432.0000\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 545420800.0000 - val_loss: 665752000.0000\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 545168320.0000 - val_loss: 670031744.0000\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 566296832.0000 - val_loss: 655427712.0000\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 619172992.0000 - val_loss: 694956992.0000\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 655151744.0000 - val_loss: 645896576.0000\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 585577408.0000 - val_loss: 644418944.0000\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 548973376.0000 - val_loss: 774306624.0000\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 555350336.0000 - val_loss: 687362112.0000\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 533828384.0000 - val_loss: 690645888.0000\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 548217216.0000 - val_loss: 662091072.0000\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 550841984.0000 - val_loss: 700569792.0000\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 551595136.0000 - val_loss: 756852288.0000\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 576042624.0000 - val_loss: 693746624.0000\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 545954176.0000 - val_loss: 683159872.0000\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 548283200.0000 - val_loss: 651979520.0000\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 530771584.0000 - val_loss: 669555392.0000\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 529289632.0000 - val_loss: 647490944.0000\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 594601728.0000 - val_loss: 664042240.0000\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 523150016.0000 - val_loss: 706098112.0000\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 545393920.0000 - val_loss: 643035200.0000\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 573992128.0000 - val_loss: 687283584.0000\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 587605952.0000 - val_loss: 707149504.0000\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 557721536.0000 - val_loss: 698915072.0000\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 527937920.0000 - val_loss: 702989824.0000\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 552444992.0000 - val_loss: 698867200.0000\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 549521600.0000 - val_loss: 645664896.0000\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 532365504.0000 - val_loss: 665306880.0000\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 543993472.0000 - val_loss: 664757312.0000\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 519190592.0000 - val_loss: 669702784.0000\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 521878784.0000 - val_loss: 684984384.0000\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 544331584.0000 - val_loss: 746355584.0000\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 571546176.0000 - val_loss: 658093952.0000\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 7ms/step - loss: 535263616.0000 - val_loss: 641036096.0000\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 531945792.0000 - val_loss: 657495808.0000\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 503733440.0000 - val_loss: 709571904.0000\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 520712832.0000 - val_loss: 689143424.0000\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 552609280.0000 - val_loss: 680865920.0000\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 549508288.0000 - val_loss: 657448320.0000\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 544639168.0000 - val_loss: 758041856.0000\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 588654784.0000 - val_loss: 798253056.0000\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 578878272.0000 - val_loss: 684869312.0000\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 545113152.0000 - val_loss: 704946304.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to the training data\n",
    "model_history = regressor.fit(X_train, y_train, model__epochs=500, model__batch_size=32,model__validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d850517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 256)               11520     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 96)                12384     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,409\n",
      "Trainable params: 73,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "51a452c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 460534656.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "460534656.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss= model.evaluate(X_test, y_test)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "056a3163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1fab1d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_train:  23495.10960978838\n",
      "R2_train:  0.8558846514781566\n",
      "**************************\n",
      "RMSE_test:  21460.07180326316\n",
      "R2_test:  0.8320247562614236\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metrics\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"RMSE_train: \", rmse_train)\n",
    "print(\"R2_train: \", r2_train)\n",
    "print('**************************')\n",
    "print(\"RMSE_test: \", rmse_test)\n",
    "print(\"R2_test: \", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e5f6730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 44698.043],\n",
       "       [ 71519.33 ],\n",
       "       [ 51958.43 ],\n",
       "       [203424.05 ],\n",
       "       [ 99147.695],\n",
       "       [ 19040.898]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0b733e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998     56990\n",
       "304     63350\n",
       "271     51018\n",
       "625    159990\n",
       "951     68999\n",
       "353     21833\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f719e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperaparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b02265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel_path(model_dir=\"SAVED_MODELS\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    fileName = time.strftime(\"Model_%Y_%m_%d_%H_%M_%S_.h5\")    \n",
    "    model_path = os.path.join(model_dir, fileName)\n",
    "    print(f\"your model will be saved at the following location\\n{model_path}\")\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7429e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your model will be saved at the following location\n",
      "SAVED_MODELS\\Model_2023_02_17_13_19_45_.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(saveModel_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6aec9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21414437",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner=RandomSearch(build_model,objective='val_loss',max_trials=5,directory='project',project_name='price-pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "091d0118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 11s]\n",
      "val_loss: 3759572992.0\n",
      "\n",
      "Best val_loss So Far: 3759572992.0\n",
      "Total elapsed time: 00h 00m 46s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d486904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 15,\n",
       " 'units_0': 96,\n",
       " 'units_1': 160,\n",
       " 'learning_rate': 0.01,\n",
       " 'units_2': 512,\n",
       " 'units_3': 96,\n",
       " 'units_4': 256,\n",
       " 'units_5': 352,\n",
       " 'units_6': 96,\n",
       " 'units_7': 512,\n",
       " 'units_8': 192,\n",
       " 'units_9': 384,\n",
       " 'units_10': 384,\n",
       " 'units_11': 352,\n",
       " 'units_12': 288,\n",
       " 'units_13': 352,\n",
       " 'units_14': 64,\n",
       " 'units_15': 448,\n",
       " 'units_16': 256,\n",
       " 'units_17': 480,\n",
       " 'units_18': 288,\n",
       " 'units_19': 192}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d292030",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53ed00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=mymodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8cbe8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12879.607],\n",
       "       [ 11681.838],\n",
       "       [ 10090.207],\n",
       "       [100590.55 ],\n",
       "       [ 13459.764],\n",
       "       [ 23925.676]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b1dd600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998     56990\n",
       "304     63350\n",
       "271     51018\n",
       "625    159990\n",
       "951     68999\n",
       "353     21833\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2a7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b962e8d4314148b39f3e0193c2981739a3b76c8cc15f8b0c9b04d48481a26909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
